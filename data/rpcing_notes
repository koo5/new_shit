rpc in python: natively seamplessly acessing multiple objects on the server. 

pizco.  
Qt-like (and Qt compatible!) signal and slot mechanism.
https://github.com/hgrecco/pizco/tree/_multiobject
The multiobject branch seems unfinished, repeating functionality and was made against an old version. The file isnt long,
keeping intact some of the pizco functionality like 'instantiate' could require more investigation
and not sure if worth it. (at least for a start i could drop "instantiate"). The things touching the io loop
are a bit arcane, maybe the gevent fork can help. 
Other option is to not rpc so seamlessly, give up on seamless object/attribute access and make the interface from method calls.
At any case, the priority of splitting lemon into rpcing components has decreased, as ive optimized it to run quite nicely as a single process (with marpa in a thread). Disorganized notes follow.

zerorpc 
doesnt have any remote attributes. Other libraries seem to be even worse, requiring
various declarations and stuff. One thing zerorpc has is streaming generators.


misc
http://morepypy.blogspot.cz/2014/11/tornado-without-gil-on-pypy-stm.html
http://nanomsg.org/

http://zeromq.github.io/pyzmq/eventloop.html
http://www.tornadoweb.org/en/stable/ioloop.html
https://github.com/zeromq/pyzmq/blob/master/zmq/eventloop/minitornado/ioloop.py
https://github.com/hgrecco/pizco/pull/22
http://twistedmatrix.com/documents/13.0.0/core/howto/threading.html

debugging the rpc server code under tornado io loop: give up trying to make it propagate exceptions,
get a scriptable debugger (unlike pycharms..)

http://nbviewer.ipython.org/gist/ChrisBeaumont/5758381/descriptor_writeup.ipynb
http://stackoverflow.com/a/26096355
http://www.tornadoweb.org/en/stable/guide/coroutines.html

"""can a client be a server at the same time? question of event loops integration i think
a not so neat but okay alternative for the distributed event handling:
make the nonlocal client frames in keybindings.py stubs that raise an error
catch and proceed to emit a signal with that event on the server (implemented in pizco in one of the forks/branches?)
then all clients try it again? or more organized, at the moment its just root and menu,
 so 'all' would work, if there will be multiple editor clients, we can have 'last active editor'
...?.?.?"""



"""
general ways that rpcing complicates things;

have to do more effort at proper mvc-y eventing, This would in some form be
necessary for best performance anyway (keeping track of dirtiness at various levels.
But the split between the server and client part of frames isnt nice..

proxying elements: wont be a performance hit, if it will, it can be easily stubbed
proxy_this() and deproxy() have to be in places tho

"""




	# lets try setting a reasonable rpc timeout on the proxy
	#and wrapping everything in a try except catching the timeout?
	#also, i will be adressing the server objects explicitly
	#instead of instantiating the client frames with references to the server counterparts
	#this way it will be easier to have it survive a reconnect/server restart..



required features of the pizco fork:
no separate remoteattribute: Proxy has a path - a list of attribute names,
and handles all accesssess. 
boxing: 



or..actually..zerorpc?
no attribute access -> what must be wrapped in functions?
signals?
"boxing":quick dumb values for when the client only needs to pass them back later
 in the serializer



""" this will be the responsibility of pizco/serialization
proxied = WeakValueDictionary()
key_counter = 0
# distributed computing is fun.
# lets work with the theoretical possibiliy that the counter
# will overflow (makes me feel a bit easier than a runaway bignum)
# the point is that we want to be sure what object the client is talking about.
# ids can repeat. This doesnt save the clients from sending events while their data is
# outdated, but at least it cant seem they reference a different object than they mean.
#
def proxy_this(v):
	global key_counter
	while key_counter in proxied:
		key_counter += 1
	proxied[key_counter] = v
	return key_counter
"""



#total split or threading? 
https://wiki.python.org/moin/GlobalInterpreterLock
http://pypy.readthedocs.org/en/latest/stm.html

add --server to main_sdl and main_curses

accepts tcp connection, creates some 
client object
  .proxy is a weakref dict from some int

for tag in tags:
  if type(tag) == ElementTag:
    proxy[len(proxy)] = weakref(node)

incrementing render(transmission) id









protocols:

http://www.jsonrpc.org/specification
https://github.com/grpc/grpc
https://thrift.apache.org/tutorial/



serialization:
http://www.oilshell.org/blog/2017/01/09.html
http://cbor2.readthedocs.io/en/latest/usage.html
https://en.wikipedia.org/wiki/Apache_Avro
https://github.com/google/flatbuffers
https://developers.google.com/protocol-buffers/docs/techniques

unsuitable:swagger


misc:
https://code.visualstudio.com/blogs/2016/06/27/common-language-protocol
https://cloud.google.com/speech/reference/rpc/




jena,redis,rethink














https://pypi.python.org/pypi/ladon


